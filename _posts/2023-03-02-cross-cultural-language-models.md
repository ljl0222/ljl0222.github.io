---
title: 一些有关跨文化差异的文献简单总结
author: ljl
date: 2023-03-02
categories: [NLP]
tags: [Transformer, Cross-Cultural Differences for Language Models]
math: true
mermaid: true
---

# 写在前面

![Desktop View](/assets/img/posts/2023-03-02-cross-cultural-language-models/8articles.png)

找到了一些努力的方向，希望自己能尽快发现科研的乐趣！

# Probing Pre-Trained Language Models for Cross-Cultural Differences in Values

## 摘要

提出在多语言下的多文化问题，尝试捕捉跨文化的价值观。将Hofstede文化维度理论和世界价值调查应用到了大规模语言模型的文化差异的评估上。

13种语言，13种国家。

主要贡献：

- 我们提出了第一个测量嵌入在大型预训练语言模型中的文化价值的研究
- 我们提出了一种通过将调查问题转换为完形填空来探测值的方法
- 我们使用三种语言模型(mBERT、XLM和XLM-r)在13种语言上进行了实验，通过两次大规模的价值调查显示了价值对齐相关性
- 我们围绕在多元文化背景下部署这些模型的潜在影响进行了讨论

可恨的是，代码没开源，去年三月份到现在都没开源了。

![Desktop View](/assets/img/posts/2023-03-02-cross-cultural-language-models/uploadedsoon.png)

## 相关工作

很多人研究过毒性信息和常识推理，以及社会当中包含价值观等有偏的信息，这里甚至做了多模态。

据他所说，没有研究搞过跨文化的价值观评估。

## 探索价值观

主要提出了三个问题：

- 预训练模型是否捕捉到了既定价值观的跨文化多样性？
- 不同预训练模型的嵌入是否有相似之处？
- 预训练模型当中嵌入的价值与现有的价值是否有关系？

## 价值调查

给出了两个不懂的词，Hofstede的文化维度理论和世界价值调查。

### 文化维度理论

用了六个文化维度，分别是权力距离(pdi)，个人主义(idv)，不确定性回避(uai)，男性气质(mas)，长期取向(lto)，放纵(ivr)。对于每个问题，Hofstede给出了定义的公式。总而言之，通过一些方法将文化映射到了国家。

### 世界价值观调查

以更详细的方式收集跨文化人群的价值观数据。这项调查开始于1981年，由一个非营利组织进行，其中包括一个国际研究人员网络。这项调查是分阶段进行的，目的是收集价值观随时间变化的数据。最新的浪潮是第七波，从2017年持续到2020年。与欧洲价值研究2相比，WVS针对所有国家和地区，包括57个国家。

大概就是问问题，WVS公布了每个问题的调查结果。这些分为11个类别:(1)腐败，(2)道德价值观和规范，(3)幸福和福祉，(4)移民，(5)政治文化和政权，(6)政治利益和政治参与，(7)宗教价值观，(8)科学和技术，(9)安全，(10)社会资本，信任和组织成员，(11)社会价值观，态度和刻板印象。

## 探索生成

为了使调查与语言模型兼容，我们将调查问题重新制定为完形填空。简单来说，感觉是去问PLMs的完型填空问题了。

### 文化维度理论 & 世界价值观调查

把设计的问题变成了hard prompt的题目，评价为啥也没干。

![Desktop View](/assets/img/posts/2023-03-02-cross-cultural-language-models/prompt.png)

### 跨多种语言检测

使用半自动的方法，将创建的探测从英语翻译成目标语言，我们使用一个涵盖所有目标语言的API。

(未完待续，现在这周还剩一天了，我还要看七篇，哈哈)

这里实际上使用的方法是使用模型将英语翻译为目标语言，将上文当中的模板方法当中的[MASK]换成标签词，来帮助保持语法结构，从而帮助翻译模型。为什么作者不自己重新翻译一遍呢，因为有人指出，翻译调查问题的时候会出现问题丢失（虽然不知道为什么用他这种方法就不丢失了8）。

在将问题由英语替换到目标语言之后，我们首先通过一些方法来检查替换后的翻译的标签，在检查的过程当中，我们实际上使用了跨语言单词对齐器，来对齐英语的词汇和对应语言当中的词，虽然没有解释这是什么东西，但是根据语义感觉还挺好理解的？比如英语当中的某些单词可能需要用其他语言当中的不止一个词来表示。最终当然还得把找到的目标词换回来，比较好笑的是，如果两种方法都没有找到目标词的话，还是得人工操作。

![Desktop View](/assets/img/posts/2023-03-02-cross-cultural-language-models/manual.png)

### 语言和国家的选择

![Desktop View](/assets/img/posts/2023-03-02-cross-cultural-language-models/language_country.png)

选取的标准是，被之前文化层面的文章调查过，而且存在于mBERT，而且在wiki上有超过10000篇条目。

## 方法

### 模型

总而言之，选了一堆多语言模型，主要是：mBERT、XLM(MLM version)、XLM-RoBERTa。

### Mask探测

没太看明白，貌似是这样的，人工标数据的时候是从1-10分标注的，所以模型评估的时候也用了一个最大概率和最小概率的对数差。同时对每一个相应问题的所有回答的量进行了归一化。

### 评估

计算了模型回答的和人回答的值之间的等级相关系数。

## 结果

仍然是根据前面所说的三个问题来计算：

- 预训练模型是否捕捉到了既定价值观的跨文化多样性？
- 不同预训练模型的嵌入是否有相似之处？
- 预训练模型当中嵌入与现有的价值是否有关系？

### RQ1

显示出了不同文化的价值观差异，由于本文用了两种方法，即WVS和Hofstede的六维方法，六维度的表现不明显，而WVS的效果还不错。

![Desktop View](/assets/img/posts/2023-03-02-cross-cultural-language-models/1F2.png)

![Desktop View](/assets/img/posts/2023-03-02-cross-cultural-language-models/1F3.png)

### RQ2

相关性很低，基本上没啥关系。不同的训练任务会得到不同的嵌入。

### RQ3

对于Hofstede的六维理论，相关性很弱。

对于WVS，貌似也没啥关系。

（绷不住了）

# Wikipedia Cultural Diversity Dataset:A Complete Cartography for 300 Language Editions

## 摘要

在本文中，我们介绍了维基百科文化多样性数据集。对于每个现有的 Wikipedia 语言版本，数据集包含表示其相关文化上下文的文章的分类，即与语言相关的所有概念和实体以及它所说的领土。我们描述了用于对文章进行分类的方法，以及我们定义提供分类器的丰富特征集，并作为数据集的一部分发布。我们提出了几个目的，我们设想使用这个数据集，包括检测、测量和反击维基百科项目中的内容差距，并鼓励数字人文领域的跨文化研究。

简单来说，造了一个多语言的上下文相关的数据集，旨在得到CCC（与编辑的地理和文化背景相关的文章（即他们的地点、传统习俗、语言、农业、传记等）文本。

## 数据集的创造

### 语言-领土映射

将语言和第一第二层次的政治划分相关联，当一种语言仅在国家的部分地区使用的时候，才使用二级层次。用ISO代码进行了识别。

### 特征描述

当我们得到前一步的结果后，我们将会获得文章和语言之间的关系（虽然前面说的是地域吧）。

定义了一些文本特征，来描述一个文本是不是CCC文本。有好多好多，通过(1)一定是；(2)有可能是；(3)一定不是；(4)有可能是；来衡量是否是CCC文本。

![Desktop View](/assets/img/posts/2023-03-02-cross-cultural-language-models/feature.png)


### 机器学习

使用随机森林分类器来学习给出的所有特征来限制是否得到CCC文本。将类别1视作可靠的CCC文章，类别0视作可靠的非CCC文章，当然也有文章同时存在两个属性，不过很少。拿到所有的类别1作为最终选择。对于负样本，用了负采样的方法，将所有不属于类别1的文本内容拿出来五个视作样本0，也就是说，我们的分类器最终训练的是属于类别1的文章和随机文章（而不是简单区分CCC文章和非CCC文章）。

### 手工评估

相较于之前的工作，做了一次更大的人工评估。

### 主要归因

我们找到的CCC文章占据了不同语言的不同比例，当然也包含了很多区域，我们设计了一个简单的启发式方法来估计每个文章被归因到了多少特定的领域。

- 地理代码代表的地区
- 文章中包含的关键词