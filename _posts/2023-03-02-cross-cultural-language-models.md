---
title: 一些有关跨文化差异的文献简单总结
author: ljl
date: 2023-03-02
categories: [NLP]
tags: [Transformer, Cross-Cultural Differences for Language Models]
math: true
mermaid: true
---

# 写在前面

![Desktop View](/assets/img/posts/2023-03-02-cross-cultural-language-models/8articles.png)

找到了一些努力的方向，希望自己能尽快发现科研的乐趣！

# Probing Pre-Trained Language Models for Cross-Cultural Differences in Values

## 摘要

提出在多语言下的多文化问题，尝试捕捉跨文化的价值观。将Hofstede文化维度理论和世界价值调查应用到了大规模语言模型的文化差异的评估上。

13种语言，13种国家。

主要贡献：

- 我们提出了第一个测量嵌入在大型预训练语言模型中的文化价值的研究
- 我们提出了一种通过将调查问题转换为完形填空来探测值的方法
- 我们使用三种语言模型(mBERT、XLM和XLM-r)在13种语言上进行了实验，通过两次大规模的价值调查显示了价值对齐相关性
- 我们围绕在多元文化背景下部署这些模型的潜在影响进行了讨论

可恨的是，代码没开源，去年三月份到现在都没开源了。

![Desktop View](/assets/img/posts/2023-03-02-cross-cultural-language-models/uploadedsoon.png)

## 相关工作

很多人研究过毒性信息和常识推理，以及社会当中包含价值观等有偏的信息，这里甚至做了多模态。

据他所说，没有研究搞过跨文化的价值观评估。

## 探索价值观

主要提出了三个问题：

- 预训练模型是否捕捉到了既定价值观的跨文化多样性？
- 不同预训练模型的嵌入是否有相似之处？
- 预训练模型当中嵌入的价值与现有的价值是否有关系？

## 价值调查

给出了两个不懂的词，Hofstede的文化维度理论和世界价值调查。

### 文化维度理论

用了六个文化维度，分别是权力距离(pdi)，个人主义(idv)，不确定性回避(uai)，男性气质(mas)，长期取向(lto)，放纵(ivr)。对于每个问题，Hofstede给出了定义的公式。总而言之，通过一些方法将文化映射到了国家。

### 世界价值观调查

以更详细的方式收集跨文化人群的价值观数据。这项调查开始于1981年，由一个非营利组织进行，其中包括一个国际研究人员网络。这项调查是分阶段进行的，目的是收集价值观随时间变化的数据。最新的浪潮是第七波，从2017年持续到2020年。与欧洲价值研究2相比，WVS针对所有国家和地区，包括57个国家。

大概就是问问题，WVS公布了每个问题的调查结果。这些分为11个类别:(1)腐败，(2)道德价值观和规范，(3)幸福和福祉，(4)移民，(5)政治文化和政权，(6)政治利益和政治参与，(7)宗教价值观，(8)科学和技术，(9)安全，(10)社会资本，信任和组织成员，(11)社会价值观，态度和刻板印象。

## 探索生成

为了使调查与语言模型兼容，我们将调查问题重新制定为完形填空。简单来说，感觉是去问PLMs的完型填空问题了。

### 文化维度理论 & 世界价值观调查

把设计的问题变成了hard prompt的题目，评价为啥也没干。

![Desktop View](/assets/img/posts/2023-03-02-cross-cultural-language-models/prompt.png)

### 跨多种语言检测

使用半自动的方法，将创建的探测从英语翻译成目标语言，我们使用一个涵盖所有目标语言的API。

(未完待续，现在这周还剩一天了，我还要看七篇，哈哈)

这里实际上使用的方法是使用模型将英语翻译为目标语言，将上文当中的模板方法当中的[MASK]换成标签词，来帮助保持语法结构，从而帮助翻译模型。为什么作者不自己重新翻译一遍呢，因为有人指出，翻译调查问题的时候会出现问题丢失（虽然不知道为什么用他这种方法就不丢失了8）。

在将问题由英语替换到目标语言之后，我们首先通过一些方法来检查替换后的翻译的标签，在检查的过程当中，我们实际上使用了跨语言单词对齐器，来对齐英语的词汇和对应语言当中的词，虽然没有解释这是什么东西，但是根据语义感觉还挺好理解的？比如英语当中的某些单词可能需要用其他语言当中的不止一个词来表示。最终当然还得把找到的目标词换回来，比较好笑的是，如果两种方法都没有找到目标词的话，还是得人工操作。

![Desktop View](/assets/img/posts/2023-03-02-cross-cultural-language-models/manual.png)

### 语言和国家的选择

![Desktop View](/assets/img/posts/2023-03-02-cross-cultural-language-models/language_country.png)

选取的标准是，被之前文化层面的文章调查过，而且存在于mBERT，而且在wiki上有超过10000篇条目。

## 方法

### 模型

总而言之，选了一堆多语言模型，主要是：mBERT、XLM(MLM version)、XLM-RoBERTa。

### Mask探测

没太看明白，貌似是这样的，人工标数据的时候是从1-10分标注的，所以模型评估的时候也用了一个最大概率和最小概率的对数差。同时对每一个相应问题的所有回答的量进行了归一化。

### 评估

计算了模型回答的和人回答的值之间的等级相关系数。

## 结果

仍然是根据前面所说的三个问题来计算：

- 预训练模型是否捕捉到了既定价值观的跨文化多样性？
- 不同预训练模型的嵌入是否有相似之处？
- 预训练模型当中嵌入与现有的价值是否有关系？

### RQ1

显示出了不同文化的价值观差异，由于本文用了两种方法，即WVS和Hofstede的六维方法，六维度的表现不明显，而WVS的效果还不错。

![Desktop View](/assets/img/posts/2023-03-02-cross-cultural-language-models/1F2.png)

![Desktop View](/assets/img/posts/2023-03-02-cross-cultural-language-models/1F3.png)

### RQ2

相关性很低，基本上没啥关系。不同的训练任务会得到不同的嵌入。

### RQ3

对于Hofstede的六维理论，相关性很弱。

对于WVS，貌似也没啥关系。

（绷不住了）

# Wikipedia Cultural Diversity Dataset:A Complete Cartography for 300 Language Editions

## 摘要

在本文中，我们介绍了维基百科文化多样性数据集。对于每个现有的 Wikipedia 语言版本，数据集包含表示其相关文化上下文的文章的分类，即与语言相关的所有概念和实体以及它所说的领土。我们描述了用于对文章进行分类的方法，以及我们定义提供分类器的丰富特征集，并作为数据集的一部分发布。我们提出了几个目的，我们设想使用这个数据集，包括检测、测量和反击维基百科项目中的内容差距，并鼓励数字人文领域的跨文化研究。

简单来说，造了一个多语言的上下文相关的数据集，旨在得到CCC（与编辑的地理和文化背景相关的文章（即他们的地点、传统习俗、语言、农业、传记等）文本。

## 数据集的创造

### 语言-领土映射

将语言和第一第二层次的政治划分相关联，当一种语言仅在国家的部分地区使用的时候，才使用二级层次。用ISO代码进行了识别。

### 特征描述

当我们得到前一步的结果后，我们将会获得文章和语言之间的关系（虽然前面说的是地域吧）。

定义了一些文本特征，来描述一个文本是不是CCC文本。有好多好多，通过(1)一定是；(2)有可能是；(3)一定不是；(4)有可能是；来衡量是否是CCC文本。

![Desktop View](/assets/img/posts/2023-03-02-cross-cultural-language-models/feature.png)


### 机器学习

使用随机森林分类器来学习给出的所有特征来限制是否得到CCC文本。将类别1视作可靠的CCC文章，类别0视作可靠的非CCC文章，当然也有文章同时存在两个属性，不过很少。拿到所有的类别1作为最终选择。对于负样本，用了负采样的方法，将所有不属于类别1的文本内容拿出来五个视作样本0，也就是说，我们的分类器最终训练的是属于类别1的文章和随机文章（而不是简单区分CCC文章和非CCC文章）。

### 手工评估

相较于之前的工作，做了一次更大的人工评估。

### 主要归因

我们找到的CCC文章占据了不同语言的不同比例，当然也包含了很多区域，我们设计了一个简单的启发式方法来估计每个文章被归因到了多少特定的领域。

- 地理代码代表的地区
- 文章中包含的关键词

对于其他的CCC文章就用一些别的方法去分，但是没仔细看。

## 数据集描述

用了CSV格式存储，最大的文件是英文wiki（265MB），整个数据集是1.67GB。

该数据集可在 Figshare 和 WikipediaCulturacy Diversity Observator 上找到。它也以所有语言（称为 ccc_old.db）的单个 SQLite 3 数据库的形式提供，它们占用 9.5GB。

### 数据集结构

列举一个大概的图，就不详细说了。

![Desktop View](/assets/img/posts/2023-03-02-cross-cultural-language-models/2T3.png)

## 应用

主要强调了三个方面的应用：

- wiki文化差距评估和改进
- 数字人文领域的学术研究
- 用户生成的基于内容的技术

然后详细说了各个应用的内容，这里就暂时不多介绍，不详细读了。

## 结论和未来工作

使用本文提出的数据集，我们希望消除维基百科中识别和促进文化多样性的一些主要障碍，以及刺激数字人文领域的跨文化研究。这些是维基百科文化多样性项目最重要的目标。该数据集可用于 300 种语言版本，并包含每篇文章与附近地理和文化实体的关系的细粒度分类，即深入了解不同语言社区如何自行定义。

发布的数据集包括分类器使用的所有特征，这些特征构成了从 Wikimedia 数据库中提取的元数据的宝贵丰富。还发布了用于处理数据并创建数据集的所有代码，以及手动评估的结果。算法和人类评估者之间高度一致表明分类的可靠性。

未来的工作主要分为以下几个方面：

- 每月创建数据集的完整自动化
- 使用新功能丰富数据集

# Using Natural Language Processing to Understand People and Culture

（写在前面，这文章还得授权下载，但是这次同济大学支楞起来啦！）

## 摘要

本文概述了自然语言处理，以及如何使用它来加深对人和文化的理解。我们概述了语言的双重作用(即反映生产者的事情和影响受众)，回顾了一些有用的文本分析方法，并讨论了这些方法如何帮助解开一系列有趣的问题。

这篇文章提供了一个关于如何使用自动文本分析来阐明人和文化的综合讨论。它回顾了最近的方法，并解释了它们如何被非专业人士应用来回答一系列研究问题。

感觉是一个泛泛而谈的文章。

## 引言

语言无处不在。它是人们表达思想、与他人交流以及消费新闻、故事和信息的方式。这就是父母如何养育孩子，领导者如何领导，销售人员如何销售。语言是医生与患者沟通的方式，研究人员与研究参与者沟通的方式，政策制定者说服公众的方式。

毫不奇怪，语言有潜力告诉我们很多关于人和文化的信息。它可以深入了解人们是谁(例如，个性)，他们的感受，他们的态度，观点和反应。此外，当在个体之间聚合时，语言可以揭示群体或社会文化背景之间的差异，以及为什么有些东西(例如产品或想法)会流行起来。

随后，作者表明了语言存在丰富的信息。而自然语言处理是做文本分析的好帮手。简单来说，作者说明了NLP的重要性。

本文概述了NLP，以及如何用它来加深理解，以及讨论了一些如何用这些自然语言处理的方法解决一些有趣的问题。

## 语言的两重作用

主要给出了两重作用。

- 反映了关于产生它的人或者人群的事情
- 影响使用这些语言或者文本的观众

### 语言反映制作人

简单来说，语言可以反映语言制作人的状态特征等，作者说，语言甚至可能预示着即将到来的分手（我没想到的是这还有文章出处的）。

![Desktop View](/assets/img/posts/2023-03-02-cross-cultural-language-models/breakup.png)

由一个群体或社会文化语境产生的语言反映或表明了关于产生它的群体或语境的事情。

总结，分析语言不仅可以反映说话的人或者群体的情况，还能洞察社会文化差异。

### 语言影响听众

作者一开始举了几个例子，隐喻的方式传播的短语更加容易被人记住，而不确定的语言可以增加注意力。不同类型的语言会有不同的影响。

综上所述，关于语言影响的研究提出了鼓励注意力、说服力或记忆力的方法。此外，它还揭示了文化上的成功。因为语言会影响消费它的观众，包含特定类型语言的项目可能会更成功。

## 解锁文本的潜力

主要是两个方面，一方面可以提升对数据的访问；另一方面，由于海量的数据存在，我们需要借助自动文本分析技术来帮助我们处理数据。

随后，作者介绍了几种常用的自动文本分析技术，包括字典，主题建模，嵌入和神经网络模型。

由于本文章貌似不是计算机科学类的文章，因此他对于各个方法的介绍都很详细。

## 讨论

语言无处不在。在醒着的时候，人们几乎每时每刻都在以某种形式创造或使用语言。语言反映了产生它的人和社会经济背景，并影响了消费它的观众。因此，语言有可能更广泛地揭示人类和文化。

但要实现这一潜力，就需要合适的工具。

这就是自然语言处理的用武之地。这些方法不仅可以以相对客观的方式解析语言的特征，而且可以大规模地这样做。因此，这些方法可以阐明一系列有趣的问题。

中间说了很多有的没的，结论是：自然语言处理允许研究人员提出新问题，并以新的方式研究古老的主题。希望更多的心理学家会采用这些工具，并开始从文字中提取智慧。

评价为：什么都还没说呢就结束了，不愧是人文领域的文章x

# Probing Pre-Trained Language Models for Disease Knowledge

这貌似是个医学文章呀，怎么感觉不是很文化。


