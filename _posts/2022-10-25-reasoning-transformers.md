---
title: Disentangling Reasoning Capabilities from Language Models with Compositional Reasoning Transformers
author: ljl
date: 2022-10-25
categories: [论文阅读, NLP]
tags: [Transformer, Reasoning]
math: true
mermaid: true
---

## 摘要

- 提出了一个统一的推理框架ReasonFormer，反映人类在复杂决策当中的**模块化**和复合推理过程

- 将表征模块(**representation module**)和推理模块(**reasoning module**)分离开来

- 将推理的过程模块化，通过并行/级联的方法动态激活和组合不同的推理模块

总的来说，将一个推理任务分为多个部分，通过一个路由模块(skill route)来激活不同的推理模块。

## 引言

**大模型不能模拟人类进行推理（感觉确实是一些废话）**

通过一个举例来说明人们进行推理的时候一般分为两个部分，先直观的理解问题(system 1)，然后进行级联的组合推理(system 2)，即经过了这样一个思考过程：回忆事实$\to$逻辑演绎$\to$回答问题。

![Desktop View](/assets/img/posts/2022-10-25-reasoning-transformers/human-reasoning.png)

然后作者做出了一个看似很符合直觉，但是总觉得没那么有道理的假设（原文当中说基于了一个心理学的什么东西）：上文所述的system 1和system 2可以解耦，且system 2当中复杂的推理过程可以分解为多个基本的推理过程，从而使得我们可以运用预训练数据来较好的分别训练不同的基本推理过程。于是，作者提出了ReasoningFormer来反映人们的复杂推理过程，具有以下的特点：

- 表示模块和推理模块解耦

- 推理模块模块化，在基本的推理技能上具有专业性

- 推理模块采用并行或者级联的方式组成，自动确定激活的推理技能和所需的推理深度（听学长的组会讲解说是有一个skill路由模块，虽然感觉有一点点魔幻）

- 整个推理框架用一个模型解决多个任务，可以seq2seq的进行训练和推理

具体的来说，整个模型貌似分为下述四个模块：

- 表示模块：用多个transformer层来学习上下文语义和对问题的直观理解

- 推理模块：通过预先训练，成为特定推理技能的专家（逻辑，命名实体识别，简单QA，常识等等，ps：笨蛋专家），因为这些技能都比较笨蛋，所以可以有大量的优质预训练资源

- 推理路由器(**reasoning router**)：决定使用哪些推理技能，什么时候结束推理

- 适配器(**adapter**)：使得可被重用的推理模块适应推理过程的不同层次

在选取基本技能的时候，我们首先需要理解事件的关键信息，回忆相关的事实知识，理解语义相关性以及事件之间的因果关系，最终为问题提取答案。(原文当中用了extracting这个单词，但是我觉得也有可能是生成)。基于上述的原因，我们选择以下基本技能：

- 逻辑能力(**logic**)

- 简单问题问答(**QA**)

- 命名实体识别(**NER**)

- 自然语言推理(**NLI**)

- **general skill**：在选定的技能当中学习共同的知识