---
title: Diffusion-LM Improves Controllable Text Generation
author: ljl
date: 2022-11-03
categories: [论文阅读, NLP]
tags: [Transformer, Reasoning]
math: true
mermaid: true
---

**这可能会是我最像技术博客的一篇博客。**

是一些下周组会要讲解的内容，但是自己其实对此也知之甚少，讲解前乃至到今天已经很紧张了，写一篇博客来明确一下自己的脉络。（顺便偷偷吐槽，扩散模型是非常数学的模型，但是自己的数学又很不行，感觉是在最紧张的时候给自己挖了一个最深的坑）

如果想说起Diffusion Model，我们要从所有的生成模型说起。

# 生成模型

## 目标

生成模型的目标是，给定训练数据，希望能获得与训练数据相同或者类似的新数据样本。举个栗子的话就是，在训练集当中给出一些🐎的照片，我们希望模型能够学习🐎的样子，从而产生看起来很像🐎的图像。（当然是不包含在训练集当中的）

从生成模型的目标当中我们可以很容易发现，我们要得到的是一个概率模型，因为每次生成模型要给出不同的🐎的图像，而不能每次都产生同一个图像。我们将产生的一系列图像（当然也不仅仅限于图像，文本等各个方面生成模型都有很广泛的应用）的概率分布记作$p(x)$。

常见的生成模型还是有很多的：GAN，VAE，Flow-based models（流模型，用的很少以至于都没听说过），Diffusion model.（扩散模型）

## 隐变量

对于许多许多不同的模态（图像，文本，音频等等），我们可以将可以观察到的真实的数据分布视为由相关的看不见的隐变量表示或生成，一般记作$z$.

> 看的博客/教程中举了一个例子，蝴蝶的颜色是由更细微的鳞片所标识出来的，我们希望能够通过颜色来反向推出鳞片的状态，这里鳞片大概就是$z$的意思。

# VAE(Auto-encoding Variational Bayes)

讲到diffusion model，也就是扩散模型，我们很难不提到各种生成模型，而生成模型的老祖宗貌似就是AE模型，我们从老祖宗的儿子VAE开始说起。

## Intuition

我们首先给定变量$x$，一般是比较高维度的变量，和隐变量$z$，假设当前的groundtruth（真实答案）为$\theta$。

我们假设$z$满足这样的分布$p_\theta(z)$，则有$p_\theta(x\mid{z})$

![Desktop View](/assets/img/posts/2022-11-03-diffusion-model/thetaxz.png)

可以看到，我们想追求的目标是根据$x$和$\phi$来尝试求得$z$，以及可以通过$\theta$和$z$求得$x$。

还没写完，先写后面一点点的

# Diffusion Model

我们前面已经提到，Diffusion Model是一个生成模型，其目的是产生与训练数据类似的真实分布。对于扩散模型，其分为扩散过程和还原过程。

## Model Process

![Desktop View](/assets/img/posts/2022-11-03-diffusion-model/model-process.png)

模型的整体流程大概如上所示，正常的diffusion过程以及反向的reverse过程。

![Desktop View](/assets/img/posts/2022-11-03-diffusion-model/train.png)

在训练过程当中，从数据集当中拿出真实的图片，在去噪的过程当中衡量去噪后的图片和原图的差距。

这里可以使用机器学习当中的$l1\ loss/l2\ loss$来衡量。

![Desktop View](/assets/img/posts/2022-11-03-diffusion-model/inference.png)

在重建过程当中，从高斯分布当中采样很多的噪声图，通过已经训练好的training phase的reverse阶段，来得到真实的图像显示。

## Diffusion Phase

如前文所说明的，扩散过程是向原图像当中逐步添加高斯噪声的过程，我们可以将整个流程表现如下图所示：

![Desktop View](/assets/img/posts/2022-11-03-diffusion-model/diffusion.png)

### 单步扩散

我们所关注的是每一步逐渐添加高斯噪声的过程，给出每一步添加高斯噪声的公式：

$$x_t=\sqrt{1-\beta_t}x_{t-1}+\sqrt{\beta_t}Z_t,Z_t\sim{N(0,\textbf{I})}$$

在添加高斯噪声的过程当中，每次向其中添加的高斯噪声的比例不同，由上式可得其由$\beta_t$决定。我们很容易能够有这样的直觉，每步向其中添加高斯噪声的比例是并不相同的，由于一开始的图像更加趋近于原图，我们稍微添加一点点高斯噪声就会能够对原先图像产生比较大的影响；而在比较靠后的添加高斯分布的过程当中，由于图像本身已经比较趋近于纯高斯噪声，我们势必向其中添加比较大比例的高斯噪声才会对图像产生比较明显的影响。

而且，对于整个的扩散步数$T$来说，我们需要保证最后的图像趋近于完全的高斯噪声，而不能包含原有的图像信息。因此这里在设置步数的时候也应该设置的比较大。

因此这里，在diffusion的过程当中，我们$\beta_t$是逐渐变大的，而在原文当中$\beta_t$是由$10^{-4}\to{2\times{10^{-2}}}$线性变化的。

### 多步扩散

我们在上节当中给出了每一步添加噪声的公式(1)：

$$x_t=f(x_{t-1})=\sqrt{1-\beta_t}x_{t-1}+\sqrt{\beta_t}Z_t,Z_t\sim{N(0,\textbf{I})}\tag{1}$$

有了一步扩散的公式，我们自然会想到，如果我们可以求得从$x_0$开始到$x_t$当中多步的扩散公式，就可以比较方便高效地训练模型，很自然的，我们可以递归的书写上面单步扩散的公式，但是这里论文聪明地做了一些处理，使得我们的计算和表示更加方便自然。

下面的内容包含大量的数学公式。

我们首先做一步换元，用$\alpha_t$来替代$1-\beta_t$，随后我们递归地书写单步扩散公式：

$$ 1-\beta_t=\alpha_t \tag{2}$$$$ x_t=\sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}Z_t \tag{3}$$$$ x_{t-1}=\sqrt{\alpha_{t-1}}x_{t-2}+\sqrt{1-\alpha_{t-1}}Z_{t-1} \tag{4}$$

我们随后将式(4)代入式(3)可得：